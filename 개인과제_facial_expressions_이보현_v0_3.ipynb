{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "개인과제_facial expressions_이보현_v0.3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2WQZUIv2APB",
        "outputId": "0e88e156-4bb2-4990-e57f-1e8bf07db9b6"
      },
      "source": [
        "#google drive 연동\n",
        "\n",
        "from google.colab import drive \n",
        "from os.path import join  \n",
        "\n",
        "root = \"/content/drive\"     \n",
        "print(root)                 \n",
        "drive.mount(root)         \n",
        "\n",
        "gdrive_path = 'My Drive/.kaggle' \n",
        "pjt_path = join(root, gdrive_path) \n",
        "print(pjt_path)\n",
        "\n",
        "print (\"Current folder is %s\" % (pjt_path) )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/.kaggle\n",
            "Current folder is /content/drive/My Drive/.kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFtFOInh2PEs",
        "outputId": "7490441f-c50d-401a-9a1b-3c8203d7e7e9"
      },
      "source": [
        "#경로 확인 및 실행\n",
        "\n",
        "%cd \"{pjt_path}\"\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/.kaggle\n",
            "fer2013.zip  kaggle.json  test\ttrain\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "id": "Vq6v2KaC3ACm",
        "outputId": "0eb5742c-4bef-45b4-8683-c5214efb75e4"
      },
      "source": [
        "#경로 내 이미지파일 확인\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('/content/drive/My Drive/.kaggle/train/surprise/Training_99984132.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APVfi58eIfEXjeSJ3lkgtDttRGMlnA46kADvnn6V5J4w+MPxJvtQa/XwhJLpqMY0ikiIRF6ZGGG489zk/pXVfCXxD4D8VLaQ3mk28d1LcLDPGi8knJ34PIIIAIr2zw74S8KWd1LEmn27WUeHWARDBYoCW+b34+td54U8W+CLnVE0fSkksLtYFYB4wBICeVwDt98D+de4fAbxxf6H4tS2d8xxYlyDzxwfzBH5V+WHjMa9b6LL4k0uBmmnl2QkDhQT97A/AVx/hjUvHmj6pZR/EfXNasW1LUxaN/YejJqDWKu237Rcxs48uAAg4CkkZJI6DpPhTFr/AIg/aD0HSZNEhhNvcT2+pX9gNlvf+XNtS4WLJaLeoLYPZl75r6V/aZ8eR/BHxBpdrY2Za11K33/a5W8uAHLBUaXGE6E5Paq3wz+Ih1Gx0LxPqmn6LqOja+7HQfEHh7WBeWsjq22WDcQrxSLgsAwwwBwcivrH4YXkFvrNrcHAhntXjBfrk4IyfwIr88IPiT4R0GD+y9ctxLGNqKrnCqvbB9v61n63/Y3iqN4NI1eCHTQA0k1xao0sS9SFkPIq18CPHXgjR/Fmm+IJf9D01p2Syut6tLdIDt80qOVjY5wx+9xjgivqT4zfDnw7+0N8ObW68LX5a8WL7Xpk2GUOQMPGH7N3x069eayv2Z/DGjaN4UHg1PCtrDFDPloY7aNF8zPL7EAAfI+/gHI5r3izaGyWw0yKJhK90qWyRp8zOxwq4HJyeOO+K/KL4vSfYNbMcUhHlKiygccAAVjX2oXeoWKeF/tbpHfMFLI+MofvH8s/nVfw9+x34f8AFnxUtfib4f8AFNxaaj4fsG+yFZXOIUQ/uDtYAoRkYORz0r7P+HvweX4MeFdU+MXwt8dawZ7+9tNV1bRb7Vp7m0Zo/lljjjldhbgxk/KmFyo45ruX1aztfE//AAk2gO1ut+iyzxqxGWPc47+/tXvv7OiOvjHRfE2q281xOkwubGzXBe7EJw4XdxlTJGf/ANdfl7+1d8M9d+HvxK1zwtqcWy90jUZbG9Qj+KNyufocZBrzPxFcjTLOyuAHZ1jIRYULO5I+6oHJb296+SLX9ur9t7TfEkvir4U6THpWlrM6Wdk2lmUvFyoEuW+ckdRjAJ9q+/8A/gmF/wAFFvF/7WWk658IfjZpEOn+LNJgUTpGhQX1u4Kh9jdCpH/1zxX12nh+++0WGnQR5W3hXJx1PQf419w/s7/AvxGw8IeMIb+2jstJikebzEJkMzlDIE7YIG05xjZnrX58f8FdfCnh+H9rvxJ4p8PQFrLXbCAtMrfunvYVVJ9vv8oJ9SSa+FfE2tPZ6xY3lzhY7YfIwH3XBwSfTGK7H4deHvhJ40tH1G40+SG9EhkkFl5XlzuTw20odrEkA44PXGTX0B8EPhJ4M8Dw3vjSTSrQ+ItfFrC9xHaRxPDb2+8xIAqgrgyNknlsknsK+qfhD4B1j4jXtpZ+H5BHcX+pQ2sUhjz8m7LkemAuc+ma/Rfwv4esPCnh6z8OaYD5FnbrFGWOS2Byx9yck+5r/9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNfl5g7e2Z3V"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdnlRexx7R_k"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.applications import VGG16,InceptionResNetV2\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7ZGV8Cf3Cgc",
        "outputId": "20a233f3-eb90-4b38-88ba-1089b688bdb8"
      },
      "source": [
        "#이미지 크기, 색상 설정 : 데이터셋 자체의 이미지 크기/색상이 정제되어있어 해당 단계는 건너뛰었음\n",
        "# Q. 구글 드라이브에도 로컬과 마찬가지로 변환한 이미지 데이터 저장이 가능한지? 코드는 무엇을 바꿔줘야 하는지\n",
        "\n",
        "train_paths = {\"../train/surprise\"\n",
        "        , \"../train/sad\"\n",
        "        , \"../train/neutral\"\n",
        "        , \"../train/happy\"\n",
        "        , \"../train/fear\"\n",
        "        , \"../train/disgust\"\n",
        "        , \"../train/angry\"}\n",
        "\n",
        "imgsize = [24, 24]\n",
        "# Grayscale\n",
        "use_gray = 1\n",
        "# Save name\n",
        "data_name = \"custom_data\"\n",
        "\n",
        "print (\"Your images should be at\")\n",
        "for i, path in enumerate(train_paths):\n",
        "    print (\" [%d/%d] %s/%s\" % (i, len(train_paths), pjt_path, path)) \n",
        "\n",
        "print (\"Data will be saved to %s\" \n",
        "       % (pjt_path + '/data/' + data_name + '.npz'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your images should be at\n",
            " [0/7] /content/drive/My Drive/.kaggle/../train/sad\n",
            " [1/7] /content/drive/My Drive/.kaggle/../train/fear\n",
            " [2/7] /content/drive/My Drive/.kaggle/../train/surprise\n",
            " [3/7] /content/drive/My Drive/.kaggle/../train/happy\n",
            " [4/7] /content/drive/My Drive/.kaggle/../train/disgust\n",
            " [5/7] /content/drive/My Drive/.kaggle/../train/neutral\n",
            " [6/7] /content/drive/My Drive/.kaggle/../train/angry\n",
            "Data will be saved to /content/drive/My Drive/.kaggle/data/custom_data.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFca8GyB6uG1",
        "outputId": "daab2208-fe47-4830-dd9b-0d2e4ae99aa7"
      },
      "source": [
        "#이미지 크기, 색상 설정\n",
        "\n",
        "test_paths = {\"../test/surprise\"\n",
        "        , \"../test/sad\"\n",
        "        , \"../test/neutral\"\n",
        "        , \"../test/happy\"\n",
        "        , \"../test/fear\"\n",
        "        , \"../test/disgust\"\n",
        "        , \"../test/angry\"}\n",
        "\n",
        "imgsize = [24, 24]\n",
        "# Grayscale\n",
        "use_gray = 1\n",
        "# Save name\n",
        "data_name = \"custom_data\"\n",
        "\n",
        "print (\"Your images should be at\")\n",
        "for i, path in enumerate(test_paths):\n",
        "    print (\" [%d/%d] %s/%s\" % (i, len(test_paths), pjt_path ,path)) \n",
        "\n",
        "print (\"Data will be saved to %s\" \n",
        "       % (pjt_path + '/data/' + data_name + '.npz'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your images should be at\n",
            " [0/7] /content/drive/My Drive/.kaggle/../test/sad\n",
            " [1/7] /content/drive/My Drive/.kaggle/../test/neutral\n",
            " [2/7] /content/drive/My Drive/.kaggle/../test/disgust\n",
            " [3/7] /content/drive/My Drive/.kaggle/../test/happy\n",
            " [4/7] /content/drive/My Drive/.kaggle/../test/angry\n",
            " [5/7] /content/drive/My Drive/.kaggle/../test/surprise\n",
            " [6/7] /content/drive/My Drive/.kaggle/../test/fear\n",
            "Data will be saved to /content/drive/My Drive/.kaggle/data/custom_data.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEC1AiUr7Au-"
      },
      "source": [
        "def rgb2gray(rgb):\n",
        "    if len(rgb.shape) is 3:\n",
        "        return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n",
        "    else:\n",
        "        # print (\"Current Image if GRAY!\")\n",
        "        return rgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ald8r94ABEA"
      },
      "source": [
        "#train/test 데이터 경로 설정\n",
        "train_dir = \"../.kaggle/train/\" \n",
        "test_dir = \"../.kaggle/test/\"   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unIMZtFfV5sf",
        "outputId": "cdb3cf7d-c6a1-490a-c11d-97d43535392f"
      },
      "source": [
        "row, col = 48, 48\n",
        "classes = 7\n",
        "\n",
        "def count_exp(path, set_):\n",
        "    dict_ = {}\n",
        "    for expression in os.listdir(path):\n",
        "        dir_ = path + expression\n",
        "        dict_[expression] = len(os.listdir(dir_))\n",
        "    df = pd.DataFrame(dict_, index=[set_])\n",
        "    #폴더명 순서 정렬\n",
        "    df = df.reindex(columns=['surprise','sad','neutral','happy','fear','disgust', 'angry'])\n",
        "    return df\n",
        "\n",
        "train_count = count_exp(train_dir, 'train')\n",
        "test_count = count_exp(test_dir, 'test')\n",
        "print(train_count)\n",
        "print(test_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       surprise   sad  neutral  happy  fear  disgust  angry\n",
            "train      3171  4830     4965   7215  4097      436   3995\n",
            "      surprise   sad  neutral  happy  fear  disgust  angry\n",
            "test       831  1247     1233   1774  1024      111    958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nksj6IKV8KE"
      },
      "source": [
        "# image_w = 28\n",
        "# image_h = 28\n",
        "  \n",
        "# X = []\n",
        "# Y = []\n",
        "\n",
        "# count = 0 # category 갯수를 카운트 하기 위한 변수\n",
        "# category_count = [] # category별로 카운트 된 것을 저장하기 위한 리스트\n",
        "\n",
        "# for idex, categorie in enumerate(categories):\n",
        "#     label = [0 for i in range(num_classes)]  # one-hot encoding\n",
        "#     label[idex] = 1\n",
        "#     image_dir = groups_folder_path + categorie + '/'\n",
        "\n",
        "#     count = 0\n",
        "\n",
        "#     for top, dir, f in os.walk(image_dir):\n",
        "#         for filename in f:\n",
        "#             print(image_dir+filename)\n",
        "#             img = cv2.imread(image_dir+filename)\n",
        "#             img = cv2.resize(img, (image_w, image_h)) # 절대 크기로 설정\n",
        "\n",
        "#             X.append(img/256)  # 이미 256으로 scaling 해 준 것인가?\n",
        "#             Y.append(label) # one-hot encoding\n",
        "\n",
        "#             count += 1 # category 갯수 카운트\n",
        "\n",
        "#     category_count.append([categorie, count]) # 총 카운트 된 카테고리 수 append\n",
        "\n",
        " \n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov4rA4N-KHuC",
        "outputId": "db1186d5-0736-4bb3-b20e-c258fcf12fd0"
      },
      "source": [
        "#data generation\n",
        "\n",
        "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
        "                                         width_shift_range = 0.1,\n",
        "                                         height_shift_range = 0.1,\n",
        "                                         horizontal_flip = True,\n",
        "                                         rescale = 1./255.,\n",
        "                                         #zoom_range = 0.2,\n",
        "                                         validation_split = 0.2\n",
        "                                        )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                    target_size = (img_size,img_size),\n",
        "                                                    batch_size = 64,\n",
        "                                                    color_mode = \"grayscale\",\n",
        "                                                    class_mode = \"categorical\",\n",
        "                                                    subset = \"training\"\n",
        "                                                   )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22968 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGwkj5RHKMVX",
        "outputId": "a8265ee4-d594-45cf-c142-792830eb199b"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale = 1./255.,\n",
        "                                         validation_split = 0.2)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n",
        "                                                              target_size = (img_size,img_size),\n",
        "                                                              batch_size = 64,\n",
        "                                                              color_mode = \"grayscale\",\n",
        "                                                              class_mode = \"categorical\",\n",
        "                                                              subset = \"validation\"\n",
        "                                                             )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1432 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y0LIQuNK0vb"
      },
      "source": [
        "model= tf.keras.models.Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten()) \n",
        "model.add(Dense(256,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "    \n",
        "model.add(Dense(512,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer = Adam(learning_rate=0.0001), \n",
        "    loss='categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3miHcxUcT7Jk"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UkznvIHm_9A",
        "outputId": "4fce4748-c88f-4a9e-c79c-24dd72880355"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "module_wrapper (ModuleWrappe (None, None, None, 32)    320       \n",
            "_________________________________________________________________\n",
            "module_wrapper_1 (ModuleWrap (None, None, None, 64)    18496     \n",
            "_________________________________________________________________\n",
            "module_wrapper_2 (ModuleWrap (None, None, None, 64)    256       \n",
            "_________________________________________________________________\n",
            "module_wrapper_3 (ModuleWrap (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_4 (ModuleWrap (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_5 (ModuleWrap (None, None, None, 128)   204928    \n",
            "_________________________________________________________________\n",
            "module_wrapper_6 (ModuleWrap (None, None, None, 128)   512       \n",
            "_________________________________________________________________\n",
            "module_wrapper_7 (ModuleWrap (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_8 (ModuleWrap (None, None, None, 128)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_9 (ModuleWrap (None, None, None, 512)   590336    \n",
            "_________________________________________________________________\n",
            "module_wrapper_10 (ModuleWra (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "module_wrapper_11 (ModuleWra (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_12 (ModuleWra (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_13 (ModuleWra (None, None, None, 512)   2359808   \n",
            "_________________________________________________________________\n",
            "module_wrapper_14 (ModuleWra (None, None, None, 512)   2048      \n",
            "_________________________________________________________________\n",
            "module_wrapper_15 (ModuleWra (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_16 (ModuleWra (None, None, None, 512)   0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_17 (ModuleWra (None, None)              0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_18 (ModuleWra (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "module_wrapper_19 (ModuleWra (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "module_wrapper_20 (ModuleWra (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_21 (ModuleWra (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "module_wrapper_22 (ModuleWra (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "module_wrapper_23 (ModuleWra (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "module_wrapper_24 (ModuleWra (None, 7)                 3591      \n",
            "=================================================================\n",
            "Total params: 4,496,903\n",
            "Trainable params: 4,492,935\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "ri0ofQmTnCjT",
        "outputId": "e6ddcaa0-defa-48a7-fffc-28ff95af8059"
      },
      "source": [
        "history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 24/359 [=>............................] - ETA: 1:32:00 - loss: 2.8316 - accuracy: 0.1556"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6d5ec6a268c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qITe_DxTnEuc"
      },
      "source": [
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "fig.set_size_inches(12,4)\n",
        "\n",
        "ax[0].plot(history.history['accuracy'])\n",
        "ax[0].plot(history.history['val_accuracy'])\n",
        "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Training Loss vs Validation Loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}